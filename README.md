# ğŸš€ Project Objective

Develop an â€œAI Catalog Complianceâ€ demonstrator:

* **Compliance layer** to detect, in images and marketing texts, anything that could breach Franceâ€™s Loi Evin
* **Two ML components**:

  1. **Object Detection** (identify bottles, prohibited labels)
  2. **NLP Classification** (analyze the textual content of a campaign)

You will cover: ingestion, EDA, feature engineering, modeling, lightweight MLOps pipeline, monitoring, documentationâ€”applying Python best practices and planning for a future GCP deployment (Cloud Run / Vertex AI).

---

## ğŸ“… Detailed 5-day working plan (+ 2 days buffer)

|                                                       Day                                                       | Key tasks              |
| :-------------------------------------------------------------------------------------------------------------: | :--------------------- |
|                                                    **Day 1**                                                    | - **Init repo & env**: |
|                                            â€¢ `git init` + Python venv                                           |                        |
| â€¢ `requirements.txt` (pandas, numpy, scikit-learn, torch, torchvision, transformers, mlflow, fastapi, uvicornâ€¦) |                        |
|                                                  â€¢ `.gitignore`                                                 |                        |

* **Dataset**:
  â€¢ Gather a small open-source dataset of alcohol bottle images
  â€¢ Simulate 100 marketing descriptions (fictitious), 50% â€œcompliantâ€ and 50% â€œnon-compliantâ€ |
  \| **Day 2** | - **Ingestion & EDA** (`src/ingestion.py`):
  â€¢ Scripts to read images and text CSVs
  â€¢ Basic cleaning (formats, duplicates)
  â€¢ Quick notebook to explore: image sizes, text lengths, classes |                                                                                                                                                                                                                                                                                   |
  \| **Day 3** | - **Image modeling** (`src/image_model.py`):
  â€¢ Use a pre-trained model (YOLOv5 or torchvision Faster R-CNN)
  â€¢ Fine-tune on your 100 annotated images (labels: `bottle` vs `no_bottle`)
  â€¢ Metrics: mAP, precision/recall for prohibited-label detection |
  \| **Day 4** | - **Text modeling** (`src/text_model.py`):
  â€¢ Transformer (DistilBERT) to classify â€œcompliantâ€ vs â€œnon-compliantâ€
  â€¢ Pipeline: tokenization â†’ training â†’ evaluation (accuracy, F1)

* **Feature engineering**:
  â€¢ For images (bounding-box size, aspect ratio)
  â€¢ For texts (length, count of regulatory keywords) |
  \| **Day 5** | - **Pipeline & lightweight MLOps** (`src/pipeline.py`):
  â€¢ Sequential orchestration: ingestion â†’ image prediction â†’ text prediction â†’ JSON report
  â€¢ Log experiments with MLflow (metrics + parameters)

* **API prototype** (`src/app.py`):
  â€¢ FastAPI exposing `/predict_image` and `/predict_text` endpoints

* **Monitoring**:
  â€¢ Sanity-check script (verify mAP and F1 > 0.75) |
  \| **Day 6** | - **Documentation**:
  â€¢ `README.md` detailing installation, execution, and project structure
  â€¢ Pipeline diagram (PNG in `docs/`)

* **Unit tests** (`tests/test_*.py`) for each module (ingestion, models, pipeline) |
  \| **Day 7** | - **Packaging & delivery**:
  â€¢ Generate final `requirements.txt` (`pip freeze > requirements.txt`)
  â€¢ Simple Dockerfile (base `python:3.10`) to package the API
  â€¢ Commit & push to GitHub (`main` branch)

* Buffer & refinements based on personal feedback |

---

## âš™ï¸ Final Git Structure

```bash
criteo-mh-ais-catalog/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # raw images + text CSVs
â”‚   â””â”€â”€ processed/           # after cleaning
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ pipeline_diagram.png
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion.py         # ingestion + EDA
â”‚   â”œâ”€â”€ image_model.py       # detection model + metrics
â”‚   â”œâ”€â”€ text_model.py        # text classification + metrics
â”‚   â”œâ”€â”€ pipeline.py          # orchestration + MLflow
â”‚   â””â”€â”€ app.py               # FastAPI endpoints
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_ingestion.py
â”‚   â”œâ”€â”€ test_image_model.py
â”‚   â”œâ”€â”€ test_text_model.py
â”‚   â””â”€â”€ test_pipeline.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```
