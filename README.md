# ğŸš€ Objectif du projet
DÃ©velopper un dÃ©monstrateur â€œAI Catalog Complianceâ€ :

- **Couche â€œConformitÃ©â€** pour dÃ©tecter sur images et sur textes marketing tout ce qui pourrait contrevenir Ã  la Loi Evin
- **Deux briques ML** :
  1. **Object Detection** (reconnaÃ®tre bouteilles, Ã©tiquettes prohibÃ©es)
  2. **NLP Classification** (analyser le contenu textuel dâ€™une campagne)

Vous couvrirez : ingestions, EDA, feature engineering, modÃ©lisation, pipeline MLOps lÃ©ger, monitoring, documentation, tout en appliquant les bonnes pratiques de dev Python et en anticipant un futur dÃ©ploiement GCP (Cloud Run / Vertex AI).

---

## ğŸ“… Planning dÃ©taillÃ© sur 5 jours ouvrÃ©s (+ 2 jours de buffer)

| Jour   | TÃ¢ches clÃ©s                                                                                                                                                                                                                                                                                                                                                                                                                                      |
|:------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Jour 1 | - **Init repo & env** :<br>  â€¢ `git init` + venv Python<br>  â€¢ `requirements.txt` (pandas, numpy, scikit-learn, torch, torchvision, transformers, mlflow, fastapi, uvicornâ€¦)<br>  â€¢ `.gitignore`<br><br>- **Jeu de donnÃ©es** :<br>  â€¢ Rassembler un petit dataset dâ€™images de bouteilles dâ€™alcool (open-source)<br>  â€¢ Simuler 100 descriptions marketing (fictives) avec 50 % â€œcompliantesâ€ et 50 % â€œnon-compliantesâ€ |
| Jour 2 | - **Ingestion & EDA** (`src/ingestion.py`) :<br>  â€¢ Scripts pour lire images et CSV textes<br>  â€¢ Nettoyage basique (formats, doublons)<br>  â€¢ Notebook rapide pour explorer : tailles images, longueur textes, classes                                                                                                                                                |
| Jour 3 | - **ModÃ©lisation Image** (`src/image_model.py`) :<br>  â€¢ Utiliser un modÃ¨le prÃ©-entraÃ®nÃ© (YOLOv5 ou torchvision Faster R-CNN)<br>  â€¢ Fine-tuning sur vos 100 images annotÃ©es (label `bottles` vs `no_bottle`)<br>  â€¢ Metrics : mAP, precision/recall pour dÃ©tection dâ€™Ã©tiquettes interdites                                             |
| Jour 4 | - **ModÃ©lisation Texte** (`src/text_model.py`) :<br>  â€¢ Transformer (DistilBERT) pour classifier â€œcompliantâ€ vs â€œnon-compliantâ€<br>  â€¢ Pipeline tokenization â†’ training â†’ Ã©valuation (accuracy, F1)<br><br>- **Feature Engineering** :<br>  â€¢ Pour images (taille boÃ®te englobante, ratio)<br>  â€¢ Pour textes (longueur, count de mots-clÃ©s rÃ©glementaires)     |
| Jour 5 | - **Pipeline & MLOps lÃ©ger** (`src/pipeline.py`) :<br>  â€¢ Orchestration sÃ©quentielle : ingestion â†’ prÃ©diction image â†’ prÃ©diction texte â†’ rapport JSON<br>  â€¢ Enregistrement dâ€™expÃ©riences avec MLflow (metrics + paramÃ¨tres)<br><br>- **Prototype dâ€™API** (`src/app.py`) :<br>  â€¢ FastAPI exposant deux endpoints `/predict_image` et `/predict_text`<br><br>- **Monitoring** :<br>  â€¢ Script de sanity checks (vÃ©rifier que mAP et F1 > seuil de 0.75) |
| Jour 6 | - **Documentation** :<br>  â€¢ `README.md` dÃ©taillant lâ€™installation, lâ€™exÃ©cution et la structure du projet<br>  â€¢ Diagramme du pipeline (PNG dans `docs/`)<br><br>- **Tests unitaires** (`tests/test_*.py`) pour chaque module (ingestion, modÃ¨les, pipeline)                                                                                                  |
| Jour 7 | - **Packaging & livraison** :<br>  â€¢ GÃ©nÃ©rer `requirements.txt` final (`pip freeze > requirements.txt`)<br>  â€¢ Dockerfile simple (base `python:3.10`) pour embarquer lâ€™API<br>  â€¢ Commit & push sur GitHub (branche `main`)<br><br>- Buffer & correctifs selon retours personnels                                                                                 |

---

## âš™ï¸ Structure Git finale

```bash
criteo-mh-ais-catalog/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # images brutes + CSV textes
â”‚   â””â”€â”€ processed/           # after cleaning
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ pipeline_diagram.png
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion.py         # ingestion + EDA
â”‚   â”œâ”€â”€ image_model.py       # dÃ©tection modÃ¨le + metrics
â”‚   â”œâ”€â”€ text_model.py        # classification texte + metrics
â”‚   â”œâ”€â”€ pipeline.py          # orchestration MLflow
â”‚   â””â”€â”€ app.py               # FastAPI endpoints
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_ingestion.py
â”‚   â”œâ”€â”€ test_image_model.py
â”‚   â”œâ”€â”€ test_text_model.py
â”‚   â””â”€â”€ test_pipeline.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
